{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historical-possibility",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-argument",
   "metadata": {},
   "source": [
    "Vamos pegar uma intui√ß√£o do k-means inicialmente. Para tanto, vamos gerar algumas bolhas (como se fossem agrupamentos pra entender como o k-means poderia ser usado para agrupar esses dados). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-defeat",
   "metadata": {},
   "source": [
    "Agora, vamos criar nossos dados. Especificamos a localiza√ß√£o dos centr√≥ides e definimos o desvio padr√£o dos dados para cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-landing",
   "metadata": {},
   "source": [
    "Agora usamos o m√©todo make_blobs para criar as bolhas baseadas nas informa√ß√µes que passamos par√¢metros. O m√©todo retorna os dados gerados bem como o r√≥tulo de cada um (seu cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-rally",
   "metadata": {},
   "source": [
    "Podemos criar uma fun√ß√£o para visualizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-saver",
   "metadata": {},
   "source": [
    "E agora, fazemos o plot das bolhas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_clusters(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-journey",
   "metadata": {},
   "source": [
    "Agora, a ideia √© treinar o k-means nesses dados e verificar se ele encontra esses grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-newark",
   "metadata": {},
   "source": [
    "Para treinar o k-means, definimos o n√∫mero de k. A partir desses dados, 5 √© um n√∫mero adequado. Entretanto, em problemas reais, a defini√ß√£o de k n√£o √© t√£o simples assim, como j√° vimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-carrier",
   "metadata": {},
   "source": [
    "Podemos comparar os centr√≥ides obtidos pelo k-means com os centr√≥ides que definimos previamente ao criar os dados. Isso nos dar√° uma ideia da qualidade dos clusters formados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-withdrawal",
   "metadata": {},
   "source": [
    "Algo interessante de se fazer √© plotar as fronteiras de decis√£o que o algoritmo encontrou e comparar com o plot original dos dados, o que nos permite identificar erros de atribui√ß√£o a um determinado cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando as fun√ß√µes para visualizar as fronteiras de decis√£o\n",
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=35, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=2, linewidths=12,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-possession",
   "metadata": {},
   "source": [
    "Agora podemos fazer o plot. O que vamos obter √© conhecido como Diagrama de Voronoi, uma forma de representar clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-trauma",
   "metadata": {},
   "source": [
    "Compare essa figura com a figura original das bolhas. Consegue identificar erros de atribui√ß√£o?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-creation",
   "metadata": {},
   "source": [
    "Fazer a predi√ß√£o de novas amostras √© particularmente simples tamb√©m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-internet",
   "metadata": {},
   "source": [
    "# O Algoritmo K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-savage",
   "metadata": {},
   "source": [
    "Depois de entendermos intuitivamente o K-means, √© hora de nos aprofundarmos na maneira em que ele constr√≥i clusters.\n",
    "\n",
    "Suponha que seja fornecido os centr√≥ides. Dessa maneira, poder√≠amos facilmente rotular todas as int√¢ncias no dataset atribuindo a cada uma delas ao cluster cujo centr√≥ide seja o mais pr√≥ximo. \n",
    "\n",
    "Alternativamente, se todos os r√≥tulos das amostras foram fornecidos, poder√≠amos localizar os centr√≥ides calculando a m√©dia de todas as amostras para cada cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-volleyball",
   "metadata": {},
   "source": [
    "Mas e se nada disso for fornecido? \n",
    "\n",
    "Podemos posicionar os centr√≥ides de maneira aleat√≥ria (selecionando k amostras aleat√≥riamente e usando suas localiza√ß√µes como centr√≥ides). Ent√£o, rotulamos as inst√¢ncias, atualizamos os centr√≥ides, rotulamos as inst√¢ncias, atualizamos os centr√≥ides e assim sucessivamente at√© que os centr√≥ides parem de se mover. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-powder",
   "metadata": {},
   "source": [
    "Vamos executar o K-means para 1, 2 e 3 itera√ß√µes e ver como os centr√≥ides v√£o se movendo bem como as inst√¢ncias atualizando seus r√≥tulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_iter1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=1, random_state=0)\n",
    "kmeans_iter2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=2, random_state=0)\n",
    "kmeans_iter3 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=3, random_state=0)\n",
    "kmeans_iter1.fit(X)\n",
    "kmeans_iter2.fit(X)\n",
    "kmeans_iter3.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(321)\n",
    "plot_data(X)\n",
    "plot_centroids(kmeans_iter1.cluster_centers_, circle_color='r', cross_color='w')\n",
    "plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "plt.tick_params(labelbottom=False)\n",
    "plt.title(\"Update the centroids (initially randomly)\", fontsize=14)\n",
    "\n",
    "plt.subplot(322)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_xlabels=False, show_ylabels=False)\n",
    "plt.title(\"Label the instances\", fontsize=14)\n",
    "\n",
    "plt.subplot(323)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_centroids=False, show_xlabels=False)\n",
    "plot_centroids(kmeans_iter2.cluster_centers_)\n",
    "\n",
    "plt.subplot(324)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_xlabels=False, show_ylabels=False)\n",
    "\n",
    "plt.subplot(325)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_centroids=False)\n",
    "plot_centroids(kmeans_iter3.cluster_centers_)\n",
    "\n",
    "plt.subplot(326)\n",
    "plot_decision_boundaries(kmeans_iter3, X, show_ylabels=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-wholesale",
   "metadata": {},
   "source": [
    "Vimos que, em poucas itera√ß√µes, o k-means se aproximou da solu√ß√£o √≥tima. Entretanto, como vimos, o k-means √© sens√≠vel a inicializa√ß√£o dos centr√≥ides, o que signifca que ele pode n√£o convergir para a solu√ß√£o √≥tima. Vamos entender como podemos encontrar a solu√ß√£o √≥tima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-chart",
   "metadata": {},
   "source": [
    "### M√©todos de Inicializa√ß√£o dos Centr√≥ides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-judge",
   "metadata": {},
   "source": [
    "Se sabmos de antem√£o onde aproximadamente os centr√≥ides devem ser posicionados, podemos setar o par√¢metro *init* a partir de um Numpy array e setar *n_init* igual a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[-3,3],[-3,2],[-3,1],[-1,2],[0,2]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-chance",
   "metadata": {},
   "source": [
    "Outra solu√ß√£o √© executar o algoritmo m√∫ltiplas vezes com diferentes inicializa√ß√µes aleat√≥rias e guardar a melhor solu√ß√£o, mas como sabemos que uma solu√ß√£o √© a melhor?\n",
    "\n",
    "Temos uma m√©trica de performance que nos fornece essa informa√ß√£o: inercia do modelo, obtida atrav√©s do par√¢metro *inertia_*. Essa m√©trica nada mais √© que dist√¢ncia m√©dia quadr√°tica entre cada inst√¢ncia e o centr√≥ide mais pr√≥ximo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-charm",
   "metadata": {},
   "source": [
    "### Encontrando o n√∫mero √≥timo de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-killer",
   "metadata": {},
   "source": [
    "At√© o momento, definimos o n√∫mero de cluster (k) igual a 5 porque √© o n√∫mero √≥bvio quando se olha os dados. Entretanto, de modo geral, n√£o ser√° f√°cil saber definir k e os resultados podem ser bem ruins se escolhermos o n√∫mero incorreto de k. \n",
    "\n",
    "Observe o exemplo quando usamos k=3 e depois k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusterer_comparison(clusterer1, clusterer2, X, title1=None, title2=None):\n",
    "    clusterer1.fit(X)\n",
    "    clusterer2.fit(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_decision_boundaries(clusterer1, X)\n",
    "    if title1:\n",
    "        plt.title(title1, fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_decision_boundaries(clusterer2, X, show_ylabels=False)\n",
    "    if title2:\n",
    "        plt.title(title2, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_k8 = KMeans(n_clusters=8, random_state=42)\n",
    "\n",
    "plot_clusterer_comparison(kmeans_k3, kmeans_k8, X, \"$k=3$\", \"$k=8$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-liberal",
   "metadata": {},
   "source": [
    "E se usarmos a in√©rcia para definir o n√∫mero √≥timo de clusters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-repeat",
   "metadata": {},
   "source": [
    "Qual o problema dessa solu√ß√£o?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-poultry",
   "metadata": {},
   "source": [
    "N√£o podemos simplesmente usar o valor de k que minimiza a in√©rcia visto que ela continuar√° diminuindo √† medida que aumentamos o valor de k. \n",
    "\n",
    "De fato, quanto mais clusters existem, mais perto cada inst√¢ncia ficar√° do seu centr√≥ide e, portanto, menor o valor da in√≠ercia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-independence",
   "metadata": {},
   "source": [
    "#### Elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-clerk",
   "metadata": {},
   "source": [
    "Entretanto, ainda podemos usar a in√©rcia para definir um valor adequado de clusters. Ao analisarmos o gr√°fico, observamos que o valor na in√©rcia cai dr√°sticamente √† medida que aumentamos o valor de k at√© 4 e, ent√£o, o valor da in√©rcia diminui muito mais lentamente a partir da√≠. Esta curva possui vagamente uma forma de um bra√ßo e possui um \"cotovelo\" (elbow) quando k=4. Assim, poder√≠amos usar k=4 para uma solu√ß√£o adequada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "             xy=(4, inertias[3]),\n",
    "             xytext=(0.55, 0.55),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=16,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(kmeans_per_k[4-1], X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-chest",
   "metadata": {},
   "source": [
    "#### Silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-dialogue",
   "metadata": {},
   "source": [
    "Uma outra, e melhor, abordagem para determinar o n√∫mero de cluster √© a partir do *silhouette coefficient*. Como vimos, esse coeficiente √© dado pela seguinte equa√ß√£o:\n",
    "\n",
    "$\\frac{(b-a)}{max(a,b)}$\n",
    "\n",
    "em que:\n",
    "\n",
    "* √© a dist√¢ncia m√©dia para outras amostras no mesmo cluster (dist√¢ncia m√©dia intra-cluster)\n",
    "* ùëè √© a dist√¢ncia m√©dia do cluster mais pr√≥ximo (dist√¢ncia m√©dia para as amostras do pr√≥ximo cluster mais pr√≥ximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-defensive",
   "metadata": {},
   "source": [
    "Para calcular o *silhouette score* podemos usar a fun√ß√£o de mesmo nome da Scikit-Learn, fornecendo todas as amostras do dataset e seus respectivos r√≥tulos aos quais foram atribu√≠dos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-landing",
   "metadata": {},
   "source": [
    "Podemos comparar o valor desse score para diferentes n√∫meros de clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-granny",
   "metadata": {},
   "source": [
    "Como podemos ver, esta visualiza√ß√£o √© muito mais rica que a anterior (usando *inertia*). Embora confirme que k=4 √© uma √≥tima escolha (da mesma maneira que o gr√°fico anterior), mostra tamb√©m que k=5 √© uma excelente op√ß√£o e muito melhor que k=6 ou k=7, o que n√£o √© vis√≠vel quando usamos in√©rcia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-mounting",
   "metadata": {},
   "source": [
    "# Hierarchical Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-education",
   "metadata": {},
   "source": [
    "Para come√ßar, vamos criar alguns dados para entender a forma√ß√£o dos dendrogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[5,3],\n",
    "    [10,15],\n",
    "    [15,12],\n",
    "    [24,10],\n",
    "    [30,30],\n",
    "    [85,70],\n",
    "    [71,80],\n",
    "    [60,78],\n",
    "    [70,55],\n",
    "    [80,91],])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-maine",
   "metadata": {},
   "source": [
    "Agora, vamos plotar esses dados para visualizar seu comportamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(X[:,0],X[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, X[:, 0], X[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-jacksonville",
   "metadata": {},
   "source": [
    "√â poss√≠vel ver que esses dados formam dois cluster. A partir deles, vamos, ent√£o, desenhar os dendrogramas. A princ√≠pio, iremos usar a biblioteca scipy (de onde vem o numpy) para isso. Depois, vamos para Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'single')\n",
    "\n",
    "labelList = range(1, 11)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-packet",
   "metadata": {},
   "source": [
    "O algoritmo come√ßa encontrando os dois pontos mais pr√≥ximos um ao outro baseado na dist√¢ncia euclidiana. No caso, os pontos 2 e 3 s√£o os mais pr√≥ximos, por isso eles formam o primeiro cluster. \n",
    "\n",
    "Nos dendrogramas, a altura das barras de cada agrupamento determina o valor da dist√¢ncia euclidiana. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-edinburgh",
   "metadata": {},
   "source": [
    "## Hclust usando Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-mention",
   "metadata": {},
   "source": [
    "Vamos agora usar a scikit learn para criar um cluster hier√°rquico. \n",
    "\n",
    "Primeiro, vamos criar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[5,3],\n",
    "    [10,15],\n",
    "    [15,12],\n",
    "    [24,10],\n",
    "    [30,30],\n",
    "    [85,70],\n",
    "    [71,80],\n",
    "    [60,78],\n",
    "    [70,55],\n",
    "    [80,91],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-piece",
   "metadata": {},
   "source": [
    "Observe que setamos o n√∫mero de cluster *n_clusters* igual a 2, usamos a dist√¢ncia euclidiana para calcular a dist√¢ncia entre os pontos e linkage estamos usando a op√ß√£o \"ward\", que se refere a minimiza√ß√£o da vari√¢ncia dos clusters sendo agrupados. As outras op√ß√µes s√£o as que vimos em sala: single linkage, complete linkage e average linkage\n",
    "\n",
    "O m√©todo fit_predict() retorna o r√≥tulo de cada inst√¢ncia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-moscow",
   "metadata": {},
   "source": [
    "Podemos plotar os dados originais pintando cada inst√¢ncia de acordo com o cluster a que ela foi atribu√≠da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c=cluster.labels_, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-system",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
